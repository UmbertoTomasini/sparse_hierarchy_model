{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32c51d0-71eb-44d4-b6db-f1853c24377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/6)*(4*27+54-42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b27d212-4ce1-4fa3-8e5b-b3a96807f47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 0., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 5., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 5., 0., 4., 5., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 5., 6., 4., 5., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 5., 6., 4., 5., 6., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 5., 6., 4., 5., 6., 7., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 5., 6., 4., 5., 6., 7., 0., 0., 7., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 5., 6., 4., 5., 6., 7., 8., 0., 7., 0., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 5., 6., 4., 5., 6., 7., 8., 0., 7., 8., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 5., 6., 4., 5., 6., 7., 8., 9., 7., 8., 0.])\n",
      "tensor([1., 2., 3., 1., 2., 3., 4., 5., 6., 4., 5., 6., 7., 8., 9., 7., 8., 9.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 1., 2., 3., 4., 5., 6., 4., 5., 6., 7., 8., 9., 7., 8., 9.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.tensor([1,2,3,4,5,6,7,8,9])\n",
    "s=3\n",
    "s0=1\n",
    "L=2\n",
    "v1 = torch.zeros((s0+1)*s**2)\n",
    "countk = 0\n",
    "for k in range(s):\n",
    "    count = 0\n",
    "    for i in range(s):\n",
    "        for j in range(s0+1):\n",
    "            v1[count+j*(s)+k*s*(s0+1)]= v[i+k*s]\n",
    "            print(v1)\n",
    "        count+=1\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c82ff18-c437-40c7-a3b1-9a8132d147f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "1\n",
      "tensor([[10, 11, 12],\n",
      "        [13, 14, 15],\n",
      "        [16, 17, 18]])\n",
      "tensor([[ 1,  2,  3, 10, 11, 12],\n",
      "        [ 4,  5,  6, 13, 14, 15],\n",
      "        [ 7,  8,  9, 16, 17, 18]])\n",
      "2\n",
      "tensor([[19, 20, 21],\n",
      "        [22, 23, 24],\n",
      "        [25, 26, 27]])\n",
      "tensor([[ 1,  2,  3, 10, 11, 12, 19, 20, 21],\n",
      "        [ 4,  5,  6, 13, 14, 15, 22, 23, 24],\n",
      "        [ 7,  8,  9, 16, 17, 18, 25, 26, 27]])\n",
      "tensor([[ 1,  2,  3, 10, 11, 12, 19, 20, 21],\n",
      "        [ 4,  5,  6, 13, 14, 15, 22, 23, 24],\n",
      "        [ 7,  8,  9, 16, 17, 18, 25, 26, 27]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "s = 3\n",
    "s0 = 2\n",
    "v = torch.arange(1,((s0+1)*s**2)+1)\n",
    "v = v.view(s,(s0+1)*s)\n",
    "for i in range(s):\n",
    "    tmp = v[i,:].view(s0+1,s)\n",
    "\n",
    "    if i==0:\n",
    "        mat = tmp\n",
    "    else:\n",
    "        mat = torch.concat((mat,tmp),dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe67ecc4-0a7c-4e84-ba7a-a696ec35e652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [10, 11, 12],\n",
      "        [19, 20, 21],\n",
      "        [ 4,  5,  6],\n",
      "        [13, 14, 15],\n",
      "        [22, 23, 24],\n",
      "        [ 7,  8,  9],\n",
      "        [16, 17, 18],\n",
      "        [25, 26, 27]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "s = 3\n",
    "s0 = 2\n",
    "\n",
    "# Create the initial tensor\n",
    "v = torch.arange(1, (s0 + 1) * s ** 2 + 1)\n",
    "\n",
    "# Directly reshape and transpose without explicit looping\n",
    "v = v.view(s, s0 + 1, s).transpose(0, 1).reshape(s * (s0 + 1), s)\n",
    "\n",
    "# Now v is equivalent to the mat in your original code\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc2f041f-5160-4da3-9790-936fd29ee0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15],\n",
      "         [16, 17, 18]]])\n",
      "tensor([[ 5,  7,  9],\n",
      "        [17, 19, 21],\n",
      "        [29, 31, 33]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  7,  9, 17, 19, 21, 29, 31, 33])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "s =3\n",
    "s0 =1\n",
    "L=2\n",
    "v = torch.arange(1,19)\n",
    "print(v)\n",
    "v=v.view(-1,s)\n",
    "# Reshape the tensor to (s, s0+1, s)\n",
    "v = v.view(s, s0 + 1, s)\n",
    "print(v)\n",
    "# Sum over the second dimension\n",
    "v = v.sum(dim=1)\n",
    "print(v)\n",
    "v.view(s**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f830e4-27cc-449f-8df5-973817fdd8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from lcn import LocallyHierarchicalNet\n",
    "from lcn_shared import LocallyHierarchicalNetShared\n",
    "\n",
    "net = LocallyHierarchicalNetShared(\n",
    "    num_layers=2,\n",
    "    input_channels=1,\n",
    "    h=1,\n",
    "    # filter_size=args.filter_size,\n",
    "    out_dim=1,\n",
    "    s =2,\n",
    "    s0 = 1,\n",
    "    sharing = 2, \n",
    "    bias=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877b944b-f015-4f8d-8409-1b79672596f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4])\n",
      "torch.Size([1, 1, 16])\n",
      "sharing self\n",
      "2\n",
      "before anything\n",
      "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "          15., 16.]]])\n",
      "torch.Size([1, 1, 2, 4])\n",
      "torch.Size([1, 1, 4])\n",
      "0\n",
      "torch.Size([1, 1, 4, 1])\n",
      "torch.Size([1, 1, 4])\n",
      "one instance of s0\n",
      "tensor([[[ 3.,  7., 19., 23.]]])\n",
      "Parameter containing:\n",
      "tensor([[[1.8860, 0.6315, 0.5515, 0.2825]]], requires_grad=True)\n",
      "x:torch.Size([1, 1, 1, 4])\n",
      "1\n",
      "torch.Size([1, 1, 4, 1])\n",
      "torch.Size([1, 1, 4])\n",
      "one instance of s0\n",
      "tensor([[[11., 15., 27., 31.]]])\n",
      "Parameter containing:\n",
      "tensor([[[1.8860, 0.6315, 0.5515, 0.2825]]], requires_grad=True)\n",
      "x:torch.Size([1, 1, 1, 2, 4])\n",
      "final\n",
      "torch.Size([1, 1, 4])\n",
      "sharing self\n",
      "0\n",
      "before anything\n",
      "tensor([[[10.0787, 16.9763, 30.2189, 23.6483]]], grad_fn=<ReluBackward0>)\n",
      "tensor([[21.6473]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s=2\n",
    "s0=1\n",
    "L=2\n",
    "print(net.hier[0].weight.shape)\n",
    "x = torch.zeros([1,1,(s*(s0+1))**L])\n",
    "for j in range((s*(s0+1))**L):\n",
    "    x[0,0,j] = j+1\n",
    "\n",
    "print(x.shape)\n",
    "print(net(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc752322-0f57-4b5f-bef4-8bbf952ec50a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#NOT SHARED\u001b[39;00m\n\u001b[1;32m      3\u001b[0m bs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/venvs/venv-for-demo/lib/python3.10/site-packages/torch/__init__.py:1239\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m special \u001b[38;5;28;01mas\u001b[39;00m special\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackcompat\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m onnx \u001b[38;5;28;01mas\u001b[39;00m onnx\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit \u001b[38;5;28;01mas\u001b[39;00m jit\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg \u001b[38;5;28;01mas\u001b[39;00m linalg\n",
      "File \u001b[0;32m~/venvs/venv-for-demo/lib/python3.10/site-packages/torch/onnx/__init__.py:12\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _onnx \u001b[38;5;28;01mas\u001b[39;00m _C_onnx\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_onnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     _CAFFE2_ATEN_FALLBACK,\n\u001b[1;32m      7\u001b[0m     OperatorExportTypes,\n\u001b[1;32m      8\u001b[0m     TensorProtoDataType,\n\u001b[1;32m      9\u001b[0m     TrainingMode,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort:skip. Keep the order instead of sorting lexicographically\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     _deprecation,\n\u001b[1;32m     14\u001b[0m     errors,\n\u001b[1;32m     15\u001b[0m     symbolic_caffe2,\n\u001b[1;32m     16\u001b[0m     symbolic_helper,\n\u001b[1;32m     17\u001b[0m     symbolic_opset7,\n\u001b[1;32m     18\u001b[0m     symbolic_opset8,\n\u001b[1;32m     19\u001b[0m     symbolic_opset9,\n\u001b[1;32m     20\u001b[0m     symbolic_opset10,\n\u001b[1;32m     21\u001b[0m     symbolic_opset11,\n\u001b[1;32m     22\u001b[0m     symbolic_opset12,\n\u001b[1;32m     23\u001b[0m     symbolic_opset13,\n\u001b[1;32m     24\u001b[0m     symbolic_opset14,\n\u001b[1;32m     25\u001b[0m     symbolic_opset15,\n\u001b[1;32m     26\u001b[0m     symbolic_opset16,\n\u001b[1;32m     27\u001b[0m     symbolic_opset17,\n\u001b[1;32m     28\u001b[0m     symbolic_opset18,\n\u001b[1;32m     29\u001b[0m     utils,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# TODO(After 1.13 release): Remove the deprecated SymbolicContext\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exporter_states\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportTypes, SymbolicContext\n",
      "File \u001b[0;32m~/venvs/venv-for-demo/lib/python3.10/site-packages/torch/onnx/symbolic_opset11.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _C\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _onnx \u001b[38;5;28;01mas\u001b[39;00m _C_onnx\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     _type_utils,\n\u001b[1;32m     14\u001b[0m     errors,\n\u001b[1;32m     15\u001b[0m     symbolic_helper,\n\u001b[1;32m     16\u001b[0m     symbolic_opset10 \u001b[38;5;28;01mas\u001b[39;00m opset10,\n\u001b[1;32m     17\u001b[0m     symbolic_opset9 \u001b[38;5;28;01mas\u001b[39;00m opset9,\n\u001b[1;32m     18\u001b[0m     utils,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_globals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GLOBALS\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _beartype, jit_utils, registration\n",
      "File \u001b[0;32m~/venvs/venv-for-demo/lib/python3.10/site-packages/torch/onnx/utils.py:34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_onnx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_C_onnx\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trace\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _C\n",
      "File \u001b[0;32m~/venvs/venv-for-demo/lib/python3.10/site-packages/torch/jit/__init__.py:24\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# These are imported so users can access them from the `torch.jit` module\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_jit_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     Final,\n\u001b[1;32m     12\u001b[0m     Future,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     unused,\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_script\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     script,\n\u001b[1;32m     26\u001b[0m     Attribute,\n\u001b[1;32m     27\u001b[0m     ScriptModule,\n\u001b[1;32m     28\u001b[0m     script_method,\n\u001b[1;32m     29\u001b[0m     RecursiveScriptClass,\n\u001b[1;32m     30\u001b[0m     RecursiveScriptModule,\n\u001b[1;32m     31\u001b[0m     ScriptWarning,\n\u001b[1;32m     32\u001b[0m     interface,\n\u001b[1;32m     33\u001b[0m     CompilationUnit,\n\u001b[1;32m     34\u001b[0m     ScriptFunction,\n\u001b[1;32m     35\u001b[0m     _ScriptProfile,\n\u001b[1;32m     36\u001b[0m     _unwrap_optional,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     trace,\n\u001b[1;32m     40\u001b[0m     trace_module,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     _get_trace_graph,\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_async\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fork, wait\n",
      "File \u001b[0;32m~/venvs/venv-for-demo/lib/python3.10/site-packages/torch/jit/_script.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrontend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_jit_def, get_default_args, get_jit_class_def\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_jit_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _qualified_name\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fuser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _graph_for, _script_method_graph_for\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_state\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     _try_get_jit_cached_function,\n\u001b[1;32m     31\u001b[0m     _try_get_jit_cached_overloads,\n\u001b[1;32m     32\u001b[0m     _set_jit_function_cache,\n\u001b[1;32m     33\u001b[0m     _set_jit_overload_cache,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m     has_torch_function, has_torch_function_unary, has_torch_function_variadic)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch \n",
    "#NOT SHARED\n",
    "bs = 2\n",
    "cin = 4\n",
    "cout = 10\n",
    "d = 4 #s=2, s0=0, L=2\n",
    "x = torch.zeros([bs,cin,d])\n",
    "w = torch.zeros([cout,cin,d])\n",
    "print(x.shape)\n",
    "print(x[:,None].shape)\n",
    "print(w.shape)\n",
    "x = x[:,None]*w\n",
    "print(x.shape)\n",
    "\n",
    "x = x.view(bs, cout, cin, d // 2, 2) # [bs, cout, cin, space // 2, 2]\n",
    "#*x.shape[:-1]\n",
    "\n",
    "x = x.sum(dim=[-1, -3])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fab2d3e-7aca-4772-9184-de16a6d8b282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 4])\n",
      "torch.Size([2, 5, 2])\n",
      "torch.Size([2, 10, 5, 2])\n",
      "torch.Size([2, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "#SHARED\n",
    "bs = 2\n",
    "cin = 5\n",
    "cout = 10\n",
    "s= 2\n",
    "s0 =1\n",
    "L=1\n",
    "d = (s*(s0+1))**L\n",
    "\n",
    "x = torch.zeros([bs,cin,d])\n",
    "w = torch.zeros([cout,cin,int(d/(s0+1))])\n",
    "print(x.shape)\n",
    "#print(w.shape)\n",
    "\n",
    "x = x.reshape(*x.shape[:-1], int(x.shape[-1]/(s0+1)),s0+1)\n",
    "x = x.sum(dim = [-1])\n",
    "print(x.shape)\n",
    "x = x[:,None]*w\n",
    "print(x.shape)\n",
    "\n",
    "x = x.view(bs, cout, cin, d // (s*(s0+1)), s) # [bs, cout, cin, space // 2, 2]\n",
    "#*x.shape[:-1]\n",
    "\n",
    "x = x.sum(dim=[-1, -3])\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb84b2a-3044-42df-aa57-8679c0b3dabc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
